{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a8a274",
   "metadata": {},
   "source": [
    "## Load the image recognition model\n",
    "<code>trt_hand_dir</code> points to the directory where [trt_pose_hand](https://github.com/NVIDIA-AI-IOT/trt_pose_hand/) is saved.  \n",
    "The <code>trt_pose_hand</code> module is a refactoring of some of the cells from [this](https://github.com/NVIDIA-AI-IOT/trt_pose_hand/blob/main/gesture_classification_live_demo.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f868a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "trt_hand_dir = '../../trt_pose_hand/'\n",
    "sys.path.append(trt_hand_dir)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8e270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trt_pose_hand\n",
    "from preprocessdata import preprocessdata\n",
    "hand_model = trt_pose_hand.Model()\n",
    "hand_model.setup(trt_hand_dir, preprocessdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8c0d9",
   "metadata": {},
   "source": [
    "## Load camera and image container\n",
    "We use <code>camera</code> to pull the frames from the CSI camera  \n",
    "<code>image_w</code> is used as a container for said frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d987f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.usb_camera import USBCamera\n",
    "from jetcam.csi_camera import CSICamera\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "# camera = USBCamera(width=WIDTH, height=HEIGHT, capture_fps=30, capture_device=1)\n",
    "# camera = CSICamera(width=hand_model.WIDTH, height=hand_model.HEIGHT, capture_fps=30)\n",
    "camera = CSICamera(width=100, height=100, capture_fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39395dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261bc2b8fefa4d78960146fd09f48e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "image_w = ipywidgets.Image(format='jpeg', width=224, height=224)\n",
    "display(image_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c7d27",
   "metadata": {},
   "source": [
    "## Define <code>get_gesture</code>\n",
    "\n",
    "This is the function we run on each frame. It uses the model loaded above to determine if there is a hand in the frame and what gesture it is in. Like so much of this notebook, it is taken from [this](https://github.com/NVIDIA-AI-IOT/trt_pose_hand/blob/main/gesture_classification_live_demo.ipynb).  \n",
    "\n",
    "The lines\n",
    "```python\n",
    "with open('jetcam.jpeg', 'wb') as f:\n",
    "    f.write(image_w.value)\n",
    "```\n",
    "will write each frame to the file \"notebooks/jetcam.jpeg\". Opening this file in a program like [feh](https://feh.finalrewind.org/) (with automatic refreshing) should provide a live feed of what the model sees. There may be a more elegant way to view the image, but I couldn't find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a9e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gesture(change):\n",
    "    image = change['new']\n",
    "    data = hand_model.preprocess(image)\n",
    "    cmap, paf = hand_model.model_trt(data)\n",
    "    cmap, paf = cmap.detach().cpu(), paf.detach().cpu()\n",
    "    counts, objects, peaks = hand_model.parse_objects(cmap, paf)\n",
    "    joints = hand_model.preprocess_data.joints_inference(image, counts, objects, peaks)\n",
    "    hand_model.draw_joints(image, joints)\n",
    "    #hand_model.draw_objects(image, counts, objects, peaks)\n",
    "    dist_bn_joints = hand_model.preprocess_data.find_distance(joints)\n",
    "    gesture = hand_model.clf.predict([dist_bn_joints,[0]*hand_model.num_parts*hand_model.num_parts])\n",
    "    gesture_joints = gesture[0]\n",
    "    hand_model.preprocess_data.prev_queue.append(gesture_joints)\n",
    "    hand_model.preprocess_data.prev_queue.pop(0)\n",
    "    hand_model.preprocess_data.print_label(image, hand_model.preprocess_data.prev_queue, hand_model.gesture_type)\n",
    "    image_w.value = bgr8_to_jpeg(image)\n",
    "    with open('jetcam.jpeg', 'wb') as f:\n",
    "        f.write(image_w.value)\n",
    "    return hand_model.gesture_type[gesture_joints-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49959f4b",
   "metadata": {},
   "source": [
    "##  Load the robot hand\n",
    "<code>thing</code> is the object we will use to control the hand. See the <code>README.md</code> for what functions it has access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0d465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import datetime as dt\n",
    "import pyrobot\n",
    "\n",
    "thing = pyrobot.Hand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab8c14",
   "metadata": {},
   "source": [
    "In what follows we define the functions that will move the hand into the specified gesture.  \n",
    "<code>flick_up</code> is used to compensate for weak rubber bands when moving a finger into the straight position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70bf2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flick_up(fingers, time):\n",
    "    thing.curl_wrist(0.65, time)\n",
    "    for fin in fingers:\n",
    "        if fin is 'pinky':\n",
    "            thing.curl_pinky(1,time)\n",
    "        if fin is 'ring':\n",
    "            thing.curl_ring(1,time)\n",
    "        if fin is 'middle':\n",
    "            thing.curl_middle(1,time)\n",
    "        if fin is 'index':\n",
    "            thing.curl_index(1,time)\n",
    "        sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a564350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fist(time):\n",
    "    clear_thumb()\n",
    "    idle_wiggle()\n",
    "    delay = .2\n",
    "    thing.curl_pinky(0, time)\n",
    "    sleep(delay)\n",
    "    thing.curl_ring(0, time)\n",
    "    sleep(delay)\n",
    "    thing.curl_middle(0, time)\n",
    "    sleep(delay)\n",
    "    thing.curl_index(0, time)\n",
    "    sleep(delay)\n",
    "    thing.wiggle_thumb(0,time)\n",
    "    sleep(.1)\n",
    "    thing.curl_thumb(0.2,time)  \n",
    "    sleep(time/1000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15700b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ok(time):\n",
    "    clear_thumb()\n",
    "    idle_wiggle()\n",
    "    delay = .1\n",
    "    flick_up(['pinky','ring','middle'], 500)\n",
    "    sleep(delay)\n",
    "    thing.curl_index(.25,time)\n",
    "    sleep(delay)\n",
    "    thing.wiggle_thumb(.7,time)\n",
    "    thing.curl_thumb(.13,time)\n",
    "    thing.curl_wrist(.6, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peace(time):\n",
    "    clear_thumb()\n",
    "    idle_wiggle()\n",
    "    delay = .1\n",
    "    flick_up(['middle', 'index'], time)\n",
    "    sleep(delay)\n",
    "    thing.wiggle_middle(.7,100)\n",
    "    thing.wiggle_index(.3,100)\n",
    "    thing.curl_pinky(0,time)\n",
    "    sleep(delay)\n",
    "    thing.curl_ring(0,time)\n",
    "    sleep(delay)\n",
    "    thing.wiggle_thumb(.5,time)\n",
    "    thing.curl_thumb(0,time)\n",
    "    thing.curl_wrist(.6, 400)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a44409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pan(time):\n",
    "    clear_thumb()\n",
    "    idle_wiggle()\n",
    "    delay = .1\n",
    "    flick_up(['index'], time)\n",
    "    sleep(delay)\n",
    "    thing.curl_pinky(0,time)\n",
    "    sleep(delay)\n",
    "    thing.curl_ring(0,time)\n",
    "    sleep(delay)\n",
    "    thing.curl_middle(0,time)\n",
    "    sleep(delay)\n",
    "    thing.wiggle_thumb(.5,time)\n",
    "    thing.curl_thumb(0,time)\n",
    "    thing.curl_wrist(.6, 400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630d8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_thumb():\n",
    "    if thing.curl_thumb_pos() < 0.19:\n",
    "        thing.curl_thumb(.19,100)\n",
    "        sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f55fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rock_on():\n",
    "    thing.curl_ring(0,500)\n",
    "    thing.curl_middle(0,500)\n",
    "    thing.wiggle_thumb(.8,500)\n",
    "    sleep(.5)\n",
    "    thing.curl_thumb(0,500)\n",
    "    while True:\n",
    "        thing.curl_wrist(.8,1500)\n",
    "        sleep(1.5)\n",
    "        thing.curl_wrist(.2,1500)\n",
    "        sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee28c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idle(time):\n",
    "    idle_wiggle()\n",
    "    clear_thumb()\n",
    "    flick_up(['pinky','ring','middle','index'], time)\n",
    "    thing.wiggle_thumb(0,100)\n",
    "    thing.curl_thumb(1,time)\n",
    "    sleep(.3)\n",
    "    thing.curl_wrist(.6,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0b6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idle_wiggle():\n",
    "    thing.wiggle_middle(0.6,100)\n",
    "    thing.wiggle_pinky(0.5,100)\n",
    "    thing.wiggle_ring(.45,100)\n",
    "    thing.wiggle_index(.5,100)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ddecc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idle(1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82cf380",
   "metadata": {},
   "source": [
    "## Mimicking time!\n",
    "We are now at last ready to play with the hand. Run this cell and put your hand in front of the camera! Once you've finished, interupt the kernel to both turn off the camera and stop sending signals to the hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    camera.running = True\n",
    "    print(f'Possible gestures: {hand_model.gesture_type}')\n",
    "    this_gesture = ''\n",
    "    current_gesture = ''\n",
    "    last_change = dt.datetime.now()\n",
    "    while True:\n",
    "        last_gesture = this_gesture\n",
    "        this_gesture = get_gesture({'new': camera.value})\n",
    "        if this_gesture is not last_gesture:\n",
    "            last_change = dt.datetime.now()\n",
    "        long_enough = (dt.datetime.now()-last_change).total_seconds() > .7\n",
    "        if long_enough and (this_gesture is not current_gesture):\n",
    "            print(f'Current gesture: {this_gesture}'.ljust(30), end='\\r')\n",
    "            if this_gesture == 'fist':\n",
    "                fist(700)\n",
    "                current_gesture = this_gesture\n",
    "            if this_gesture == 'stop':\n",
    "                idle(700)\n",
    "                current_gesture = this_gesture\n",
    "            if this_gesture == 'ok':\n",
    "                ok(700)\n",
    "                current_gesture = this_gesture\n",
    "            if this_gesture == 'peace':\n",
    "                peace(700)\n",
    "                current_gesture = this_gesture\n",
    "            if this_gesture == 'pan':\n",
    "                pan(700)\n",
    "                current_gesture = this_gesture\n",
    "except KeyboardInterrupt:\n",
    "    idle(700)\n",
    "    camera.running = False\n",
    "    print('Camera off'.ljust(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
